{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import os\n",
    "import io\n",
    "import zipfile\n",
    "import shapefile\n",
    "from shapely.geometry import Point, shape\n",
    "from shapely import geometry\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import fiona\n",
    "from fiona.crs import from_epsg\n",
    "from osgeo import gdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set workspace\n",
    "os.chdir(r'E:\\ArcGIS_2\\Lab2')\n",
    "wksp = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. TEMPERATURE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull weather information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 153 weather stations of the Minnesota network selecting a random day\n",
    "link = r'https://mesonet.agron.iastate.edu/api/1/daily.geojson?date=2023-03-15&network=MN_RWIS'\n",
    "info = json.loads(requests.get(link).text)\n",
    "location = []\n",
    "for i in range(len(info['features'])):\n",
    "    # Store the station and its coordinates\n",
    "    location.append({'station': info['features'][i]['properties']['station'], \n",
    "                     'coordinates': info['features'][i]['geometry']['coordinates']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Daily weather data from 2023\n",
    "url = r'https://mesonet.agron.iastate.edu/api/1/daily.geojson?network=MN_RWIS&year=2023'\n",
    "weather = json.loads(requests.get(url).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Delete all the unneeded weather variables and keep only minimum and maximum temperature\n",
    "delete = [\n",
    "      \"tmpf_est\",\n",
    "      \"precip\",\n",
    "      \"precip_est\",\n",
    "      \"max_gust\",\n",
    "      \"snow\",\n",
    "      \"snowd\",\n",
    "      \"min_rh\",\n",
    "      \"max_rh\",\n",
    "      \"min_dwpf\",\n",
    "      \"max_dwpf\",\n",
    "      \"min_feel\",\n",
    "      \"max_feel\",\n",
    "      \"min_rstage\",\n",
    "      \"max_rstage\",\n",
    "      \"temp_hour\",\n",
    "      \"max_gust_localts\",\n",
    "      \"max_drct\",\n",
    "      \"avg_feel\", \n",
    "      \"avg_sknt\", \n",
    "      \"vector_avg_drct\", \n",
    "      \"id\"\n",
    "]\n",
    "\n",
    "for i in range(len(weather['features'])):\n",
    "    for key in delete:\n",
    "        del weather['features'][i]['properties'][key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull Minnesota boundary from MGC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, March 20, 2023 9:56:05 PM\",\"Succeeded at Monday, March 20, 2023 9:56:06 PM (Elapsed Time: 0.87 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\ArcGIS_2\\\\Lab2\\\\minnesota.shp'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MN boundary\n",
    "mn_url = \"https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_dot/bdry_state/shp_bdry_state.zip\"\n",
    "boundaries = requests.post(mn_url)\n",
    "zipfile.ZipFile(io.BytesIO(boundaries.content)).extractall(wksp)\n",
    "\n",
    "# Project shp\n",
    "sr = arcpy.SpatialReference(4326)\n",
    "arcpy.Project_management('Boundaries_of_Minnesota.shp', 'minnesota.shp', sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ranges_intersect(range1, range2):\n",
    "    \"\"\"\n",
    "    Returns True if the two ranges intersect, False otherwise.\n",
    "    Each range is a tuple of two numbers representing the minimum and maximum values of the range.\n",
    "    \"\"\"\n",
    "    if range1[1] < range2[0] or range2[1] < range1[0]:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the optimum range is 62-99 F, but a different range is used to train the code as the temperature recorded for 2023 is still below the optimum range due to the winter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Optimum temperature\n",
    "lower_temp = 10 #62\n",
    "upper_temp = 50 #99\n",
    "opt_temp = range(lower_temp, upper_temp+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the shapefile data for Minnesota\n",
    "sf = shapefile.Reader(\"minnesota.shp\")\n",
    "shapes = sf.shapes()\n",
    "state_border = shapes[0]\n",
    "\n",
    "# Create a shapely Polygon object from the state border shape\n",
    "border_polygon = shape(state_border)\n",
    "\n",
    "# Create an empty list to add the not useful readings\n",
    "wrong = []\n",
    "\n",
    "# Add all the not useful readings to a list\n",
    "for i in range(len(weather['features'])):\n",
    "    \n",
    "    # Readings whose temp readings are None\n",
    "    if weather['features'][i]['properties']['min_tmpf'] == None or weather['features'][i]['properties']['max_tmpf'] == None:\n",
    "        wrong.append(weather['features'][i])\n",
    "        continue\n",
    "    \n",
    "    # Stations outside of Minnesota\n",
    "    point = Point(weather['features'][i]['geometry']['coordinates'])\n",
    "    if not border_polygon.contains(point):\n",
    "        wrong.append(weather['features'][i])\n",
    "        continue\n",
    "        \n",
    "    # Readings whose min and max temp are the same. This is an indicator of wrong data\n",
    "    if weather['features'][i]['properties']['min_tmpf'] == weather['features'][i]['properties']['max_tmpf']:\n",
    "        wrong.append(weather['features'][i])\n",
    "        continue\n",
    "        \n",
    "    # Readings whose temp is outside of the optimum range\n",
    "    lower_limit = math.floor(weather['features'][i]['properties']['min_tmpf'])\n",
    "    upper_limit = math.ceil(weather['features'][i]['properties']['max_tmpf'])\n",
    "    range_temp = range(lower_limit, upper_limit)\n",
    "    \n",
    "    # Readings not representative of the broader region if max and min temp are similar\n",
    "    if len(range_temp) == 1:\n",
    "        wrong.append(weather['features'][i]) \n",
    "        continue\n",
    "    \n",
    "# Delete the not useful readings \n",
    "for element in wrong:\n",
    "    weather['features'].remove(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly average temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10]:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "stations = []\n",
    "# Add the dictionaries to a data frame\n",
    "for j in range(len(weather['features'])):\n",
    "    stations.append(weather['features'][j]['properties'])\n",
    "df = pd.DataFrame.from_dict(stations)\n",
    "\n",
    "# Remove the day part from the date leaving only year and month\n",
    "for i in range(len(df['date'])):\n",
    "    df['date'][i] = df['date'][i][:7]\n",
    "    \n",
    "# Get monthly average min and max temperature for each station\n",
    "grouped = df.groupby(['station', 'date', 'name']).agg('mean')\n",
    "grouped.reset_index(inplace=True)\n",
    "\n",
    "# Return data to a dictionary\n",
    "mean = grouped.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add the geometry to the stations\n",
    "mean_tmp = []\n",
    "for i in range(len(mean)):\n",
    "    for j in range(len(location)):\n",
    "        if mean[i]['station'] == location[j]['station']:\n",
    "            mean_tmp.append({'type': 'Feature', 'properties': mean[i], \n",
    "                             'geometry': {'type': 'Point', 'coordinates': location[j]['coordinates']}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove monthly average temperature if outside of the optimum range\n",
    "bad_data = []\n",
    "for i in range(len(mean_tmp)):\n",
    "    lower_limit = math.floor(mean_tmp[i]['properties']['min_tmpf'])\n",
    "    upper_limit = math.ceil(mean_tmp[i]['properties']['max_tmpf'])\n",
    "    range_temp = range(lower_limit, upper_limit)\n",
    "    # Temperature outside the optimum range is flagged\n",
    "    if ranges_intersect(opt_temp, range_temp) == False:\n",
    "        bad_data.append(mean_tmp[i])\n",
    "        \n",
    "# Delete the not useful readings \n",
    "for element in bad_data:\n",
    "    mean_tmp.remove(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stations shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema =  {'geometry': 'Point', 'properties': {'station': 'str', 'date': 'str', 'name': 'str', 'max_tmpf': 'float', 'min_tmpf': 'float'}}\n",
    "\n",
    "with fiona.open(\"stations.shp\", 'w', crs = from_epsg(4326), driver = 'ESRI Shapefile', schema = schema) as output:\n",
    "    for i in range(len(mean_tmp)):\n",
    "          # geometry\n",
    "          point = Point(mean_tmp[i]['geometry']['coordinates'])\n",
    "          # attributes\n",
    "          prop = mean_tmp[i]['properties']\n",
    "          # write the row (geometry + attributes in GeoJSON format)\n",
    "          output.write({'geometry': geometry.mapping(point), 'properties':prop})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. LAND COVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve Land Cover Data\n",
    "lcover_url = \"https://resources.gisdata.mn.gov/pub/gdrs/data/pub/edu_umn/base_landcover_minnesota/tif_base_landcover_minnesota.zip\"\n",
    "lcover_data = requests.get(lcover_url, verify=True)\n",
    "zipfile.ZipFile(io.BytesIO(lcover_data.content)).extractall(wksp)\n",
    "lcover = \"landcover_impervious_statewide2013_v2.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>table td#td0  {font-weight: bold}</style><table class=\"notebook\"><colgroup><col style=\"width:45%\"></col><col style=\"width:55%\"></col></colgroup><tr><td id = \"td0\" title=\"catalogPath\">catalogPath</td><td title=\"E:\\ArcGIS_2\\Lab2\\landcover_impervious_statewide2013_v2.tif\">E:\\ArcGIS_2\\Lab2\\landcover_impervious_statewide2013_v2.tif</td></tr><tr><td id = \"td0\" title=\"dataType\">dataType</td><td title=\"RasterLayer\">RasterLayer</td></tr></table><p class=\"gpresult\">For additional help,     see <a href=\"#\" onclick=\"chrome.webview.postMessage('describe_helpid_120003803');return false;\">arcpy.Describe</a></p><br>"
      ],
      "text/plain": [
       "<geoprocessing describe data object object at 0x00000221032EAB70>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcover_lyr = arcpy.MakeRasterLayer_management(lcover, \"Land Cover MN\")\n",
    "\n",
    "# Build pyramids\n",
    "arcpy.BuildPyramids_management(lcover_lyr)\n",
    "\n",
    "# Calculate statistics\n",
    "arcpy.CalculateStatistics_management(lcover_lyr)\n",
    "\n",
    "# Verify the source file and data type\n",
    "arcpy.Describe(lcover_lyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, March 20, 2023 10:02:57 PM\",\"Minimum = 0.000000\",\"Succeeded at Monday, March 20, 2023 10:02:57 PM (Elapsed Time: 0.02 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result '0'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the Raster layer to dataset for extracting properties\n",
    "lcover_dataset = os.path.join(wksp, \"lcover_dataset.tif\")\n",
    "arcpy.CopyRaster_management(lcover_lyr, lcover_dataset)\n",
    "arcpy.management.GetRasterProperties(lcover_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify land cover raster is within MN boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All pixels are within the boundary.\n"
     ]
    }
   ],
   "source": [
    "# Check all pixels are within the boundary    \n",
    "# Get shapefile extent\n",
    "with arcpy.da.SearchCursor('minnesota.shp' , ['SHAPE@']) as cursor:\n",
    "    for row in cursor:\n",
    "        shape_extent = row[0].extent\n",
    "\n",
    "# Extract raster cells within shapefile extent\n",
    "out_raster = arcpy.sa.ExtractByMask(lcover_dataset, 'minnesota.shp')\n",
    "\n",
    "# Check if all pixels are within the boundary\n",
    "result = arcpy.GetRasterProperties_management(out_raster, \"MAXIMUM\")\n",
    "max_val = float(result.getOutput(0))\n",
    "\n",
    "if max_val > 0:\n",
    "    print(\"All pixels are within the boundary.\")\n",
    "else:\n",
    "    print(\"There are pixels outside the boundary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for incorrect values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nodata value is 255.0.\n"
     ]
    }
   ],
   "source": [
    "# Load the raster file\n",
    "ds = gdal.Open(lcover_dataset)\n",
    "band = ds.GetRasterBand(1)\n",
    "\n",
    "# Read the raster data as a numpy array\n",
    "data = band.ReadAsArray()\n",
    "\n",
    "# Check for missing values\n",
    "if np.any(np.isnan(data)):\n",
    "    print('There are missing values in the raster.')\n",
    "\n",
    "# Check for negative values\n",
    "if np.any(data < 0):\n",
    "    print('There are negative values in the raster.')\n",
    "\n",
    "# Check the nodata value\n",
    "nodata = band.GetNoDataValue()\n",
    "if nodata is None:\n",
    "    print('There is no nodata value set for the raster.')\n",
    "else:\n",
    "    print(f'The nodata value is {nodata}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project and convert raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, March 20, 2023 10:16:24 PM\",\"Succeeded at Monday, March 20, 2023 10:18:14 PM (Elapsed Time: 1 minutes 49 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\ArcGIS_2\\\\Lab2\\\\landcover_projected.tif'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Project raster to WGS 1984\n",
    "sr = arcpy.SpatialReference(4326)\n",
    "arcpy.ProjectRaster_management(\"lcover_dataset.tif\", os.path.join(wksp, 'landcover_projected.tif'), sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecuteError",
     "evalue": "ERROR 000651: Non simple.\nFailed to execute (RasterToPolygon).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mExecuteError\u001b[0m                              Traceback (most recent call last)",
      "In  \u001b[0;34m[15]\u001b[0m:\nLine \u001b[0;34m1\u001b[0m:     arcpy.conversion.RasterToPolygon(\n",
      "File \u001b[0;34mC:\\Users\\osori050\\AppData\\Local\\Programs\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\conversion.py\u001b[0m, in \u001b[0;32mRasterToPolygon\u001b[0m:\nLine \u001b[0;34m772\u001b[0m:   \u001b[34mraise\u001b[39;49;00m e\n",
      "File \u001b[0;34mC:\\Users\\osori050\\AppData\\Local\\Programs\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\conversion.py\u001b[0m, in \u001b[0;32mRasterToPolygon\u001b[0m:\nLine \u001b[0;34m769\u001b[0m:   retval = convertArcObjectToPythonObject(gp.RasterToPolygon_conversion(*gp_fixargs((in_raster, out_polygon_features, simplify, raster_field, create_multipart_features, max_vertices_per_feature), \u001b[34mTrue\u001b[39;49;00m)))\n",
      "File \u001b[0;34mC:\\Users\\osori050\\AppData\\Local\\Programs\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\geoprocessing\\_base.py\u001b[0m, in \u001b[0;32m<lambda>\u001b[0m:\nLine \u001b[0;34m512\u001b[0m:   \u001b[34mreturn\u001b[39;49;00m \u001b[34mlambda\u001b[39;49;00m *args: val(*gp_fixargs(args, \u001b[34mTrue\u001b[39;49;00m))\n",
      "\u001b[0;31mExecuteError\u001b[0m: ERROR 000651: Non simple.\nFailed to execute (RasterToPolygon).\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Convert raster to polygon to upload to PostGIS\n",
    "arcpy.conversion.RasterToPolygon(\n",
    "    in_raster=os.path.join(wksp, \"landcover_projected.tif\"),\n",
    "    out_polygon_features=os.path.join(wksp, \"landcover.shp\"),\n",
    "    simplify=\"SIMPLIFY\",\n",
    "    raster_field=\"Value\",\n",
    "    create_multipart_features=\"SINGLE_OUTER_PART\",\n",
    "    max_vertices_per_feature=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. STINK BUG OBSERVATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve Stinkbugs Data\n",
    "sbug_url = \"https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_mda/biota_bmsb/shp_biota_bmsb.zip\"\n",
    "sbug_data = requests.get(sbug_url, verify=True)\n",
    "zipfile.ZipFile(io.BytesIO(sbug_data.content)).extractall(wksp)\n",
    "sbug = \"BMSBSurveyDataTable.dbf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "aprx = arcpy.mp.ArcGISProject(\"CURRENT\")\n",
    "aprxMap = aprx.listMaps(\"Map\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stinkbug data table\n",
    "sbugtable = arcpy.TableToTable_conversion(sbug, wksp, \"sbugtable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create point layer of data table\n",
    "x_field = \"Longitude\"\n",
    "y_field = \"Latitude\"\n",
    "output_fc = \"sbug_points\"\n",
    "spatial_reference = arcpy.SpatialReference(4326)\n",
    "sbug_points = arcpy.management.XYTableToPoint(sbugtable, \n",
    "                                              output_fc, \n",
    "                                              x_field, \n",
    "                                              y_field, \n",
    "                                              \"\", \n",
    "                                              spatial_reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify points are within Minnesota boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run intersect tool on points and MN boundary\n",
    "intersect = arcpy.Intersect_analysis([sbug_points, 'minnesota.shp'], \"point_intersect.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select points that fall within the boundary of Minnesota and create new layer\n",
    "arcpy.MakeFeatureLayer_management(sbug_points, \"points_lyr\")\n",
    "selected_points = arcpy.SelectLayerByLocation_management(\"points_lyr\", \"INTERSECT\", 'minnesota.shp')\n",
    "MN_sbugpoints = arcpy.CopyFeatures_management(\"points_lyr\", \"intersected_points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = arcpy.GetCount_management(MN_sbugpoints)\n",
    "count = int(result.getOutput(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All points are within the boundary of Minnesota.\n"
     ]
    }
   ],
   "source": [
    "# Verify resulting layer only includes points within MN boundary\n",
    "total_points = int(arcpy.GetCount_management(MN_sbugpoints).getOutput(0))\n",
    "if count == total_points:\n",
    "    print(\"All points are within the boundary of Minnesota.\")\n",
    "else:\n",
    "    print(\"Some points are outside the boundary of Minnesota.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify observation counts are within acceptable range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set acceptable count range\n",
    "acceptable_range = [0, 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to store invalid and valid observations\n",
    "invalid_observations = []\n",
    "valid_observations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for valid/invalid observations and append them to their respective lists\n",
    "with arcpy.da.SearchCursor(MN_sbugpoints, [\"Adults\", \"Nymphs\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] >= acceptable_range[0] and row[0] <= acceptable_range[1]:\n",
    "            # Add the valid observation to the list\n",
    "            valid_observations.append(row)\n",
    "            \n",
    "            if row[1] >= acceptable_range[0] and row[1] <= acceptable_range[1]:\n",
    "                # Add the valid observation to the list\n",
    "                valid_observations.append(row)\n",
    "            else:\n",
    "                # Add the invalid observation to the list\n",
    "                invalid_observations.append(row)\n",
    "                \n",
    "        else:\n",
    "            # Add the invalid observation to the list\n",
    "            invalid_observations.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(invalid_observations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve DEM from MGC\n",
    "dem_output = requests.post(r'https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_dnr/elev_30m_digital_elevation_model/fgdb_elev_30m_digital_elevation_model.zip')\n",
    "zipfile.ZipFile(io.BytesIO(dem_output.content)).extractall(wksp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, March 15, 2023 5:41:19 PM\",\"Building Pyramids...\",\"Calculating Statistics...\",\"Succeeded at Wednesday, March 15, 2023 5:41:50 PM (Elapsed Time: 30.78 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\ArcGIS_2\\\\Lab2\\\\DEM.tif'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.join(wksp, 'DEM.tif')\n",
    "\n",
    "# Create a copy of the raster in the workspace\n",
    "arcpy.management.CopyRaster(\n",
    "    in_raster=r'/elev_30m_digital_elevation_model.gdb/digital_elevation_model_30m',\n",
    "    out_rasterdataset=path,\n",
    "    config_keyword=\"\",\n",
    "    background_value=None,\n",
    "    nodata_value=\"32767\",\n",
    "    onebit_to_eightbit=\"NONE\",\n",
    "    colormap_to_RGB=\"NONE\",\n",
    "    pixel_type=\"\",\n",
    "    scale_pixel_value=\"NONE\",\n",
    "    RGB_to_Colormap=\"NONE\",\n",
    "    format=\"TIFF\",\n",
    "    transform=\"NONE\",\n",
    "    process_as_multidimensional=\"CURRENT_SLICE\",\n",
    "    build_multidimensional_transpose=\"NO_TRANSPOSE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raster QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial Reference of DEM:  NAD_1983_UTM_Zone_15N\n",
      "Cell Size of DEM: 30.0 x 30.0\n",
      "Nodata values found in DEM\n",
      "Minimum elevation value in DEM is correct\n",
      "Maximum elevation value in DEM is correct\n"
     ]
    }
   ],
   "source": [
    "# Set input DEM\n",
    "dem = \"DEM.tif\"\n",
    "\n",
    "# Check the spatial reference of the DEM\n",
    "desc = arcpy.Describe(dem)\n",
    "sr = desc.spatialReference\n",
    "print(\"Spatial Reference of DEM: \", sr.name)\n",
    "\n",
    "# Check the cell size of the DEM\n",
    "cellSizeX = desc.meanCellWidth\n",
    "cellSizeY = desc.meanCellHeight\n",
    "print(\"Cell Size of DEM: {} x {}\".format(cellSizeX, cellSizeY))\n",
    "\n",
    "# Check for any nodata values in the DEM\n",
    "nodata = arcpy.sa.SetNull(dem, dem, \"VALUE = {}\".format(desc.noDataValue))\n",
    "if arcpy.management.GetRasterProperties(nodata, \"MAXIMUM\") == 0:\n",
    "    print(\"No nodata values found in DEM\") # This is expected due since MN isn't a rectangle\n",
    "else:\n",
    "    print(\"Nodata values found in DEM\")\n",
    "\n",
    "# Check the minimum and maximum elevation values in the DEM\n",
    "highest_point = [2301-50, 2301+50]\n",
    "lowest_point = [602-50, 602+50]\n",
    "\n",
    "minimum = int(arcpy.management.GetRasterProperties(dem, \"MINIMUM\").getOutput(0))\n",
    "maximum = int(arcpy.management.GetRasterProperties(dem, \"MAXIMUM\").getOutput(0))\n",
    "\n",
    "if minimum >= lowest_point[0] and minimum <= lowest_point[1]:\n",
    "    print(\"Minimum elevation value in DEM is correct\")\n",
    "else:\n",
    "    print(f\"Minimum elevation value in DEM is {minimum} and should be close to {lowest_point}\")\n",
    "    \n",
    "if maximum >= highest_point[0] and maximum <= highest_point[1]:\n",
    "    print(\"Maximum elevation value in DEM is correct\")\n",
    "else:\n",
    "    print(f\"Maximum elevation value in DEM is {maximum} and should be close to {highest_point}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raster transformation to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 16, 2023 5:37:26 PM\",\"Succeeded at Thursday, March 16, 2023 5:38:09 PM (Elapsed Time: 43.06 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\ArcGIS_2\\\\Lab2\\\\DEM_projected.tif'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Project DEM to WGS 1984\n",
    "sr = arcpy.SpatialReference(4326)\n",
    "output = os.path.join(wksp, 'DEM_projected.tif')\n",
    "arcpy.ProjectRaster_management(dem, output, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 16, 2023 8:17:16 PM\",\"Building Pyramids...\",\"Succeeded at Thursday, March 16, 2023 8:17:21 PM (Elapsed Time: 5.03 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\ArcGIS_2\\\\Lab2\\\\DEM_resampled.tif'>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Increase the cell size \n",
    "arcpy.management.Resample(\n",
    "    in_raster=\"DEM_projected.tif\",\n",
    "    out_raster=os.path.join(wksp, 'DEM_resampled.tif'),\n",
    "    cell_size=\"0.03 0.03\",\n",
    "    resampling_type=\"MAJORITY\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 16, 2023 8:16:58 PM\",\"Succeeded at Thursday, March 16, 2023 8:17:00 PM (Elapsed Time: 2.04 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\ArcGIS_2\\\\Lab2\\\\elevation.shp'>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create elevation points from DEM\n",
    "arcpy.conversion.RasterToPoint(\n",
    "    in_raster=\"DEM_resampled.tif\",\n",
    "    out_point_features=os.path.join(wksp, 'elevation.shp'),\n",
    "    raster_field=\"Value\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. SAVE TO POSTGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to postgresql database\n",
    "connection = psycopg2.connect(host = '',\n",
    "                              port = '',\n",
    "                              database = '',\n",
    "                              user = '',\n",
    "                              password = '',\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature (stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\"stations.shp\")\n",
    "# fields I want from shapefile\n",
    "fields = [\"station\", \"date\", \"name\", \"max_tmpf\", \"min_tmpf\", \"Shape@WKT\"]\n",
    "\n",
    "# Create SQL table\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"DROP TABLE IF EXISTS stations\")\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE stations (\n",
    "        id SERIAL,\n",
    "        station VARCHAR,\n",
    "        date VARCHAR,\n",
    "        name VARCHAR,\n",
    "        max_tmpf DOUBLE PRECISION,\n",
    "        min_tmpf DOUBLE PRECISION)\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT AddGeometryColumn('stations', 'geom', 4326, 'POINT', 2)\n",
    "\"\"\")\n",
    "\n",
    "# Populate PostGIS\n",
    "with arcpy.da.SearchCursor(data, fields) as da_cursor:\n",
    "    for row in da_cursor:\n",
    "        wkt = row[5]\n",
    "        cursor.execute(\"INSERT INTO stations (station, date, name, max_tmpf, min_tmpf, geom) VALUES (%s, %s, %s, %s, %s, ST_GeomFromText(%s, 4326))\", (row[0], row[1], row[2], row[3], row[4], wkt))\n",
    "\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Land cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### There was issues trying to convert the DEM to a polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = ('elevation.shp')\n",
    "fields_points = ['pointid', 'grid_code', \"Shape@WKT\"]\n",
    "\n",
    "# Create SQL table\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"DROP TABLE IF EXISTS elevation\")\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE elevation (\n",
    "        id SERIAL,\n",
    "        pointid INT,\n",
    "        grid_code INT)\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT AddGeometryColumn('elevation', 'geom', 4326, 'POINT', 2)\n",
    "\"\"\")\n",
    "\n",
    "# Populate PostGIS\n",
    "with arcpy.da.SearchCursor(points, fields_points) as da_cursor:\n",
    "    for row in da_cursor:\n",
    "        wkt = row[2]\n",
    "        cursor.execute(\"INSERT INTO elevation (pointid, grid_code, geom) VALUES (%s, %s, ST_GeomFromText(%s, 4326))\", (row[0], row[1], wkt))\n",
    "\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stink bug observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = (r'E:\\ArcGIS_2\\Lab2\\Lab2.gdb\\intersected_points')\n",
    "fields_observations = ['SiteName', \n",
    "                       'SiteType', \n",
    "                       'City', \n",
    "                       'County', \n",
    "                       'Latitude', \n",
    "                       'Longitude', \n",
    "                       'SurveyName',\n",
    "                       'Scientific',\n",
    "                       'CommonName',\n",
    "                       'Surveyor',\n",
    "                       'Year',\n",
    "                       'TrapID',\n",
    "                       'TrapType',\n",
    "                       'Lure',\n",
    "                       'CheckDate',\n",
    "                       'Adults',\n",
    "                       'Nymphs',\n",
    "                       'Notes',\n",
    "                       \"Shape@WKT\"]\n",
    "\n",
    "# Create SQL table\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"DROP TABLE IF EXISTS observations\")\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE observations (\n",
    "        id SERIAL,\n",
    "        SiteName VARCHAR,\n",
    "        SiteType VARCHAR,\n",
    "        City VARCHAR,\n",
    "        County VARCHAR,\n",
    "        Latitude DOUBLE PRECISION,\n",
    "        Longitude DOUBLE PRECISION,\n",
    "        SurveyName VARCHAR,\n",
    "        Scientific VARCHAR,\n",
    "        CommonName VARCHAR,\n",
    "        Surveyor VARCHAR,\n",
    "        Year INT,\n",
    "        TrapID VARCHAR,\n",
    "        TrapType VARCHAR,\n",
    "        Lure VARCHAR,\n",
    "        CheckDate DATE,\n",
    "        Adults DOUBLE PRECISION,\n",
    "        Nymphs DOUBLE PRECISION,\n",
    "        Notes VARCHAR)\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT AddGeometryColumn('observations', 'geom', 4326, 'POINT', 2)\n",
    "\"\"\")\n",
    "\n",
    "# Populate PostGIS\n",
    "with arcpy.da.SearchCursor(observations, fields_observations) as da_cursor:\n",
    "    for row in da_cursor:\n",
    "        wkt = row[18]\n",
    "        cursor.execute(\"INSERT INTO observations (SiteName, SiteType, City, County, Latitude, Longitude, SurveyName, Scientific, CommonName, Surveyor, Year, TrapID, TrapType, Lure, CheckDate, Adults, Nymphs, Notes, geom) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, ST_GeomFromText(%s, 4326))\",\n",
    "                       (row[0], row[1], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[9], row[10], row[11], row[12], row[13], row[14], row[15], row[16], row[17], wkt))\n",
    "\n",
    "connection.commit()\n",
    "\n",
    "# Close database connection\n",
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
