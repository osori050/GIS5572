{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import requests\n",
    "import os\n",
    "import psycopg2\n",
    "import random\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set workspace\n",
    "os.chdir(r'E:\\ArcGIS_2\\Lab3')\n",
    "wksp = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, April 11, 2023 5:14:16 PM\",\"Succeeded at Tuesday, April 11, 2023 5:14:26 PM (Elapsed Time: 9.70 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'elevation'>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve elevation data from PostGIS database\n",
    "arcpy.management.MakeQueryLayer(\n",
    "    input_database=os.path.join(wksp, \"\"),\n",
    "    out_layer_name=\"elevation\",\n",
    "    query=\"SELECT * FROM elevation;\",\n",
    "    oid_fields=\"pointid\",\n",
    "    shape_type=\"POINT\",\n",
    "    srid=\"4326\",\n",
    "    spatial_reference='GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]];-400 -400 1000000000;-100000 10000;-100000 10000;8.98315284119521E-09;0.001;0.001;IsHighPrecision',\n",
    "    spatial_properties=\"DEFINE_SPATIAL_PROPERTIES\",\n",
    "    m_values=\"DO_NOT_INCLUDE_M_VALUES\",\n",
    "    z_values=\"DO_NOT_INCLUDE_Z_VALUES\",\n",
    "    extent=\"0 0 0 0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, April 11, 2023 5:14:46 PM\",\"Succeeded at Tuesday, April 11, 2023 5:14:55 PM (Elapsed Time: 8.60 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\ArcGIS_2\\\\Lab3\\\\elevation.shp'>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a copy of the elevation as a shapefile in the workspace\n",
    "arcpy.management.CopyFeatures(\n",
    "    in_features=\"elevation\",\n",
    "    out_feature_class=os.path.join(wksp, \"elevation.shp\"),\n",
    "    config_keyword=\"\",\n",
    "    spatial_grid_1=None,\n",
    "    spatial_grid_2=None,\n",
    "    spatial_grid_3=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input point dataset to be sampled\n",
    "elev_data = \"elevation.shp\"\n",
    "\n",
    "# Output point layers for elevation and reference samples\n",
    "elev_sample = \"elev_sample.shp\"\n",
    "ref_sample = \"ref_sample.shp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The percentage of data to sample is set to 1. Given the density of available elevation points, 1 percent of data will give enough data to interpolate but avoid overfitting the data. It will also shorten processing time for accuracy assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample percentage \n",
    "sample_pct = 1\n",
    "\n",
    "# Get the number of features in the input shapefile\n",
    "num_features = int(arcpy.GetCount_management(elev_data).getOutput(0))\n",
    "ref_num_features = int(arcpy.GetCount_management(elev_data).getOutput(0))  # reference sample\n",
    "\n",
    "# Calculate the number of features to sample\n",
    "num_sample = int((sample_pct / 100) * num_features)\n",
    "ref_num_sample = int((sample_pct / 100) * ref_num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of random feature IDs to select for elevation sample\n",
    "id_list = random.sample(range(1, num_features+1), num_sample)\n",
    "\n",
    "# Create a list of random feature IDs to select for reference sample\n",
    "ref_id_list = random.sample(range(1, ref_num_features+1), ref_num_sample)\n",
    "\n",
    "# Convert the lists to sets and find the common points. \n",
    "common_elements = set(id_list) & set(ref_id_list)\n",
    "\n",
    "# Remove common points from reference sample list\n",
    "ref_id_list = [item for item in ref_id_list if item not in common_elements]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, April 11, 2023 5:24:07 PM\",\"Succeeded at Tuesday, April 11, 2023 5:24:09 PM (Elapsed Time: 2.07 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\ArcGIS_2\\\\Lab3\\\\ref_sample.shp'>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the lists to comma-separated strings\n",
    "id_str = \",\".join(str(x) for x in id_list)\n",
    "ref_id_str = \",\".join(str(x) for x in ref_id_list)\n",
    "\n",
    "# Create a SQL query to select the randomly sampled features for elevation sample\n",
    "sql = '\"FID\" IN ({})'.format(id_str)\n",
    "\n",
    "# Create a SQL query to select the randomly sampled features for reference sample\n",
    "refsql = '\"FID\" IN ({})'.format(ref_id_str)\n",
    "\n",
    "# Use the Select_analysis tool to select the features and write them to new shapefiles\n",
    "arcpy.Select_analysis(elev_data, elev_sample, sql)\n",
    "arcpy.Select_analysis(elev_data, ref_sample, refsql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, April 11, 2023 9:42:49 PM\",\"Succeeded at Tuesday, April 11, 2023 9:42:51 PM (Elapsed Time: 2.25 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result ''>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpolate the elevation using 3 methods: IDW, Kriging, and GPI\n",
    "\n",
    "arcpy.ddd.Idw(\n",
    "    in_point_features=elev_sample,\n",
    "    z_field=\"grid_code\",\n",
    "    out_raster=os.path.join(wksp, \"IDW_DEM.tif\"),\n",
    "    cell_size=0.1,\n",
    "    power=2,\n",
    "    search_radius=\"VARIABLE 12\",\n",
    "    in_barrier_polyline_features=None\n",
    ")\n",
    "\n",
    "arcpy.ddd.Kriging(\n",
    "    in_point_features=elev_sample,\n",
    "    z_field=\"grid_code\",\n",
    "    out_surface_raster=os.path.join(wksp, \"Kriging_DEM.tif\"),\n",
    "    semiVariogram_props=\"Spherical 0.021245 # # #\",\n",
    "    cell_size=0.1,\n",
    "    search_radius=\"VARIABLE 12\",\n",
    "    out_variance_prediction_raster=None\n",
    ")\n",
    "\n",
    "arcpy.ga.GlobalPolynomialInterpolation(\n",
    "    in_features=elev_sample,\n",
    "    z_field=\"grid_code\",\n",
    "    out_ga_layer=None,\n",
    "    out_raster=os.path.join(wksp, \"GPI_DEM.tif\"),\n",
    "    cell_size=0.1,\n",
    "    power=1,\n",
    "    weight_field=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Accuracy assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_assessment (raster, validation_data):\n",
    "    \"\"\"\n",
    "    Calculate the RMSE of the interpolations by comparing the values to the validation data\n",
    "    \n",
    "    Input:\n",
    "    - raster: interpolation method\n",
    "    - validation_data: ground truth \n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    # Output name and path of the shapefile comparing ground truth vs classified\n",
    "    output_acc = 'Acc_' + Path(raster).stem + '.shp'\n",
    "    acc_table = os.path.join(wksp, output_acc)\n",
    "    \n",
    "    # Output name and path of the table that saves the RMSE for each interpolation\n",
    "    output_stat = 'Acc_' + Path(raster).stem + '_stat.dbf'\n",
    "    stat_table = os.path.join(wksp, output_stat)\n",
    "    \n",
    "    # Extract the predicted values and save them to the validation data's attribute table\n",
    "    arcpy.sa.ExtractValuesToPoints(\n",
    "        in_point_features=validation_data,\n",
    "        in_raster=raster,\n",
    "        out_point_features=acc_table,\n",
    "        interpolate_values=\"NONE\",\n",
    "        add_attributes=\"ALL\"\n",
    "    )\n",
    "    \n",
    "    # Rename the default fields \n",
    "    arcpy.management.CalculateField(\n",
    "        in_table=acc_table,\n",
    "        field=\"GrndTruth\",\n",
    "        expression=\"!grid_code!\",\n",
    "        expression_type=\"PYTHON3\",\n",
    "        code_block=\"\",\n",
    "        field_type=\"FLOAT\",\n",
    "        enforce_domains=\"NO_ENFORCE_DOMAINS\"\n",
    "    )\n",
    "    arcpy.management.CalculateField(\n",
    "        in_table=acc_table,\n",
    "        field=\"Classified\",\n",
    "        expression=\"!RASTERVALU!\",\n",
    "        expression_type=\"PYTHON3\",\n",
    "        code_block=\"\",\n",
    "        field_type=\"FLOAT\",\n",
    "        enforce_domains=\"NO_ENFORCE_DOMAINS\"\n",
    "    )\n",
    "    arcpy.management.DeleteField(\n",
    "        in_table=acc_table,\n",
    "        drop_field=\"grid_code;RASTERVALU\",\n",
    "        method=\"DELETE_FIELDS\"\n",
    "    )\n",
    "    \n",
    "    # Calculate the squared error\n",
    "    arcpy.management.CalculateField(\n",
    "        in_table=acc_table,\n",
    "        field=\"Sq_error\",\n",
    "        expression=\"math.pow(!GrndTruth! - !Classified!, 2)\",\n",
    "        expression_type=\"PYTHON3\",\n",
    "        code_block=\"\",\n",
    "        field_type=\"FLOAT\",\n",
    "        enforce_domains=\"NO_ENFORCE_DOMAINS\"\n",
    "    )\n",
    "    \n",
    "    # Create a new statistic table and calculate RMSE\n",
    "    arcpy.analysis.Statistics(\n",
    "        in_table=acc_table,\n",
    "        out_table=stat_table,\n",
    "        statistics_fields=\"Sq_error SUM\",\n",
    "        case_field=None,\n",
    "        concatenation_separator=\"\"\n",
    "    )    \n",
    "    arcpy.management.CalculateField(\n",
    "        in_table=stat_table,\n",
    "        field=\"RMSE\",\n",
    "        expression=\"math.sqrt(!SUM_Sq_err! / !FREQUENCY!)\",\n",
    "        expression_type=\"PYTHON3\",\n",
    "        code_block=\"\",\n",
    "        field_type=\"FLOAT\",\n",
    "        enforce_domains=\"NO_ENFORCE_DOMAINS\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists with the raster names of the interpolations with and without extension\n",
    "interpolations = ['IDW_DEM.tif', 'Kriging_DEM.tif', 'GPI_DEM.tif']\n",
    "interpolators  = ['IDW_DEM', 'Kriging_DEM', 'GPI_DEM']\n",
    "\n",
    "# Run the accuracy assesment for each interpolation\n",
    "for i in range(len(interpolations)):\n",
    "    accuracy_assessment(interpolations[i], elev_sample)\n",
    "\n",
    "# Merge the accuracy tables     \n",
    "arcpy.management.Merge(\n",
    "    inputs=\"Acc_IDW_DEM_stat.dbf;Acc_Kriging_DEM_stat.dbf;Acc_GPI_DEM_stat.dbf\",\n",
    "    output=\"Accuracy_assessment_DEM.dbf\",\n",
    "    field_mappings='Interpolat \"Interpolat\" true true false 255 Text 0 0,First,#;FREQUENCY \"FREQUENCY\" true true false 10 Long 0 10,First,#,Acc_IDW_stat,FREQUENCY,-1,-1,Acc_Kriging_stat,FREQUENCY,-1,-1,Acc_GPI_stat,FREQUENCY,-1,-1;SUM_Sq_err \"SUM_Sq_err\" true true false 19 Double 0 0,First,#,Acc_IDW_stat,SUM_Sq_err,-1,-1,Acc_Kriging_stat,SUM_Sq_err,-1,-1,Acc_GPI_stat,SUM_Sq_err,-1,-1;RMSE \"RMSE\" true true false 13 Float 0 0,First,#,Acc_IDW_stat,RMSE,-1,-1,Acc_Kriging_stat,RMSE,-1,-1,Acc_GPI_stat,RMSE,-1,-1',\n",
    "    add_source=\"NO_SOURCE_INFO\"\n",
    ")\n",
    "\n",
    "# Update the merged table with the name of each interpolator\n",
    "with arcpy.da.UpdateCursor(\"Accuracy_assessment_DEM.dbf\", ['Interpolat']) as cursor:\n",
    "    for i, row in enumerate(cursor):\n",
    "        if i < len(interpolators):\n",
    "            row[0] = interpolators[i]\n",
    "        else:\n",
    "            break\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "# Delete the cursor to release locks on the data\n",
    "del cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the interpolator with the lowest RMSE\n",
    "methods = {}\n",
    "fields = [\"Interpolat\", \"RMSE\"]\n",
    "with arcpy.da.SearchCursor('Accuracy_assessment_DEM.dbf', fields) as cursor:\n",
    "    for row in cursor:\n",
    "        methods[row[0]] = row[1]\n",
    "\n",
    "best_interpolator = min(methods, key=methods.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, April 11, 2023 9:54:46 PM\",\"Succeeded at Tuesday, April 11, 2023 9:54:49 PM (Elapsed Time: 2.67 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\ArcGIS_2\\\\Lab3\\\\IDW_DEM.shp'>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clip interpolation to MN borders \n",
    "output_clip = os.path.join(wksp, best_interpolator + '_mn.tif')\n",
    "out_raster = arcpy.sa.ExtractByMask(\n",
    "    in_raster=best_interpolator+'.tif',\n",
    "    in_mask_data=\"minnesota.shp\",\n",
    "    extraction_area=\"INSIDE\",\n",
    "    analysis_extent='-97.239102895829 43.499445217943 -89.6516983029999 49.0583312990001 GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]]'\n",
    ")\n",
    "out_raster.save(output_clip)\n",
    "\n",
    "# Convert raster to point shapefile\n",
    "output_point_shp = os.path.join(wksp, best_interpolator + '.shp')\n",
    "arcpy.conversion.RasterToPoint(\n",
    "    in_raster=output_clip,\n",
    "    out_point_features=output_point_shp,\n",
    "    raster_field=\"Value\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save to PostGIS database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to PostGIS database\n",
    "connection = psycopg2.connect(host = '',\n",
    "                              port = '',\n",
    "                              database = '',\n",
    "                              user = '',\n",
    "                              password = '',\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Accuracy assessment table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path and fields of the data to load to the database\n",
    "data = os.path.join(wksp, \"Accuracy_assessment_DEM.dbf\")\n",
    "fields = [\"OID\", \"Interpolat\", \"FREQUENCY\", \"SUM_Sq_err\", \"RMSE\"]\n",
    "\n",
    "# Create SQL table\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"DROP TABLE IF EXISTS accuracy_assessment_dem\")\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE accuracy_assessment_dem (\n",
    "        OID INT,\n",
    "        Interpolat VARCHAR,\n",
    "        FREQUENCY INT,\n",
    "        SUM_Sq_err DOUBLE PRECISION,\n",
    "        RMSE DOUBLE PRECISION)\n",
    "\"\"\")\n",
    "\n",
    "# Populate table\n",
    "with arcpy.da.SearchCursor(data, fields) as da_cursor:\n",
    "    for row in da_cursor:\n",
    "        cursor.execute(\"INSERT INTO accuracy_assessment_dem (OID, Interpolat, FREQUENCY, SUM_Sq_err, RMSE) VALUES (%s, %s, %s, %s, %s)\", (row[0], row[1], row[2], row[3], row[4]))\n",
    "\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Best interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table name with the name of the best interpolator\n",
    "point_table = best_interpolator.lower()\n",
    "\n",
    "fields = [\"pointid\", \"grid_code\", \"Shape@WKT\"]\n",
    "\n",
    "# Create SQL table\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(f\"DROP TABLE IF EXISTS {point_table}\")\n",
    "cursor.execute(f\"\"\"\n",
    "    CREATE TABLE {point_table} (\n",
    "        pointid INT,\n",
    "        grid_code DOUBLE PRECISION)\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(f\"\"\"\n",
    "    SELECT AddGeometryColumn('{point_table}', 'geom', 4326, 'POINT', 2)\n",
    "\"\"\")\n",
    "\n",
    "# Populate table\n",
    "with arcpy.da.SearchCursor(output_point_shp, fields) as da_cursor:\n",
    "    for row in da_cursor:\n",
    "        wkt = row[2]\n",
    "        cursor.execute(f\"INSERT INTO {point_table} (pointid, grid_code, geom) VALUES (%s, %s, ST_GeomFromText(%s, 4326))\", (row[0], row[1], wkt))\n",
    "\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Error table for best interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of the shapefile\n",
    "data = os.path.join(wksp, 'Acc_' + best_interpolator + '.shp')\n",
    "\n",
    "# Create the table name to use in PostGIS database\n",
    "table_name = best_interpolator.lower() + '_error_estimation'\n",
    "\n",
    "fields = [\"GrndTruth\", \"Classified\", \"Sq_error\", \"Shape@WKT\"]\n",
    "\n",
    "# Create SQL table\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "cursor.execute(f\"\"\"\n",
    "    CREATE TABLE {table_name} (\n",
    "        GrndTruth DOUBLE PRECISION,\n",
    "        Classified DOUBLE PRECISION,\n",
    "        Sq_error DOUBLE PRECISION)\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(f\"\"\"\n",
    "    SELECT AddGeometryColumn('{table_name}', 'geom', 4326, 'POINT', 2)\n",
    "\"\"\")\n",
    "\n",
    "# Populate table\n",
    "with arcpy.da.SearchCursor(data, fields) as da_cursor:\n",
    "    for row in da_cursor:\n",
    "        wkt = row[3]\n",
    "        cursor.execute(f\"INSERT INTO {table_name} (GrndTruth, Classified, Sq_error, geom) VALUES (%s, %s, %s, ST_GeomFromText(%s, 4326))\", (row[0], row[1], row[2], wkt))\n",
    "\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connection\n",
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
