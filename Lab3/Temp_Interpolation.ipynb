{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import requests\n",
    "import os\n",
    "import psycopg2\n",
    "import random\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set workspace\n",
    "os.chdir(r'E:\\ArcGIS_2\\Lab3')\n",
    "wksp = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, April 11, 2023 5:04:13 PM\",\"Succeeded at Tuesday, April 11, 2023 5:04:15 PM (Elapsed Time: 1.32 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'temp_stations'>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve temperature data from PostGIS database\n",
    "arcpy.management.MakeQueryLayer(\n",
    "    input_database=os.path.join(wksp, \"\"),\n",
    "    out_layer_name=\"temp_stations\",\n",
    "    query=\"SELECT id, min_tmpf, geom FROM stations WHERE date = '2023-03'\",\n",
    "    oid_fields=\"id\",\n",
    "    shape_type=\"POINT\",\n",
    "    srid=\"4326\",\n",
    "    spatial_reference='GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]];-400 -400 1000000000;0 1;0 1;8.98315284119521E-09;2;2;IsHighPrecision',\n",
    "    spatial_properties=\"DO_NOT_DEFINE_SPATIAL_PROPERTIES\",\n",
    "    m_values=\"DO_NOT_INCLUDE_M_VALUES\",\n",
    "    z_values=\"DO_NOT_INCLUDE_Z_VALUES\",\n",
    "    extent='-98.0690216979786 43.2052294998382 -88.6618510633838 49.6779752981444 GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]]'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, April 11, 2023 5:04:19 PM\",\"Succeeded at Tuesday, April 11, 2023 5:04:20 PM (Elapsed Time: 0.93 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\ArcGIS_2\\\\Lab3\\\\temp_stations.shp'>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a copy of the temperature as a shapefile in the workspace\n",
    "arcpy.management.CopyFeatures(\n",
    "    in_features=\"temp_stations\",\n",
    "    out_feature_class=os.path.join(wksp, \"temp_stations.shp\"),\n",
    "    config_keyword=\"\",\n",
    "    spatial_grid_1=None,\n",
    "    spatial_grid_2=None,\n",
    "    spatial_grid_3=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to input temperature, and output training and validation shapefiles\n",
    "input_shapefile = \"temp_stations.shp\"\n",
    "training_shapefile = os.path.join(wksp, \"training_shapefile.shp\")\n",
    "validation_shapefile = os.path.join(wksp, \"validation_shapefile.shp\")\n",
    "\n",
    "# Set the percentage of features to use for training\n",
    "training_percent = 70\n",
    "\n",
    "# Create a list of ObjectIDs for all features in the input shapefile\n",
    "all_ids = [row[0] for row in arcpy.da.SearchCursor(input_shapefile, [\"OID@\"])]\n",
    "\n",
    "# Calculate the number of features to use for training\n",
    "num_training = int((len(all_ids) * training_percent) / 100)\n",
    "\n",
    "# Randomly select the ObjectIDs for the training features\n",
    "training_ids = random.sample(all_ids, num_training)\n",
    "\n",
    "# Create separate lists of ObjectIDs for the validation and training features\n",
    "validation_ids = [id for id in all_ids if id not in training_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, April 11, 2023 5:04:37 PM\",\"Succeeded at Tuesday, April 11, 2023 5:04:37 PM (Elapsed Time: 0.53 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\ArcGIS_2\\\\Lab3\\\\validation_shapefile.shp'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the selected ObjectIDs to create new shapefiles for \n",
    "# i) training \n",
    "training = arcpy.management.SelectLayerByAttribute(input_shapefile, \"NEW_SELECTION\", \"FID IN {}\".format(tuple(training_ids)))\n",
    "arcpy.management.CopyFeatures(training, training_shapefile)\n",
    "\n",
    "# ii) validation \n",
    "validation = arcpy.management.SelectLayerByAttribute(input_shapefile, \"NEW_SELECTION\", \"FID IN {}\".format(tuple(validation_ids)))\n",
    "arcpy.management.CopyFeatures(validation, validation_shapefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, April 11, 2023 5:07:45 PM\",\"Succeeded at Tuesday, April 11, 2023 5:07:46 PM (Elapsed Time: 0.93 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result ''>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpolate the temperature using 3 methods: IDW, Kriging, and GPI\n",
    "\n",
    "arcpy.ddd.Idw(\n",
    "    in_point_features=\"training_shapefile.shp\",\n",
    "    z_field=\"min_tmpf\",\n",
    "    out_raster=os.path.join(wksp, \"IDW.tif\"),\n",
    "    cell_size=0.1,\n",
    "    power=2,\n",
    "    search_radius=\"VARIABLE 12\",\n",
    "    in_barrier_polyline_features=None\n",
    ")\n",
    "\n",
    "arcpy.ddd.Kriging(\n",
    "    in_point_features=\"training_shapefile.shp\",\n",
    "    z_field=\"min_tmpf\",\n",
    "    out_surface_raster=os.path.join(wksp, \"Kriging.tif\"),\n",
    "    semiVariogram_props=\"Spherical 0.021245 # # #\",\n",
    "    cell_size=0.1,\n",
    "    search_radius=\"VARIABLE 12\",\n",
    "    out_variance_prediction_raster=None\n",
    ")\n",
    "\n",
    "arcpy.ga.GlobalPolynomialInterpolation(\n",
    "    in_features=\"training_shapefile.shp\",\n",
    "    z_field=\"min_tmpf\",\n",
    "    out_ga_layer=None,\n",
    "    out_raster=os.path.join(wksp, \"GPI.tif\"),\n",
    "    cell_size=0.1,\n",
    "    power=1,\n",
    "    weight_field=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Accuracy assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_assessment (raster, validation_data):\n",
    "    \"\"\"\n",
    "    Calculate the RMSE of the interpolations by comparing the values to the validation data\n",
    "    \n",
    "    Input:\n",
    "    - raster: interpolation method\n",
    "    - validation_data: ground truth \n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    # Output name and path of the shapefile comparing ground truth vs classified\n",
    "    output_acc = 'Acc_' + Path(raster).stem + '.shp'\n",
    "    acc_table = os.path.join(wksp, output_acc)\n",
    "    \n",
    "    # Output name and path of the table that saves the RMSE for each interpolation\n",
    "    output_stat = 'Acc_' + Path(raster).stem + '_stat.dbf'\n",
    "    stat_table = os.path.join(wksp, output_stat)\n",
    "    \n",
    "    # Extract the predicted values and save them to the validation data's attribute table\n",
    "    arcpy.sa.ExtractValuesToPoints(\n",
    "        in_point_features=validation_data,\n",
    "        in_raster=raster,\n",
    "        out_point_features=acc_table,\n",
    "        interpolate_values=\"NONE\",\n",
    "        add_attributes=\"ALL\"\n",
    "    )\n",
    "    \n",
    "    # Rename the default fields \n",
    "    arcpy.management.CalculateField(\n",
    "        in_table=acc_table,\n",
    "        field=\"GrndTruth\",\n",
    "        expression=\"!min_tmpf!\",\n",
    "        expression_type=\"PYTHON3\",\n",
    "        code_block=\"\",\n",
    "        field_type=\"FLOAT\",\n",
    "        enforce_domains=\"NO_ENFORCE_DOMAINS\"\n",
    "    )\n",
    "    arcpy.management.CalculateField(\n",
    "        in_table=acc_table,\n",
    "        field=\"Classified\",\n",
    "        expression=\"!RASTERVALU!\",\n",
    "        expression_type=\"PYTHON3\",\n",
    "        code_block=\"\",\n",
    "        field_type=\"FLOAT\",\n",
    "        enforce_domains=\"NO_ENFORCE_DOMAINS\"\n",
    "    )\n",
    "    arcpy.management.DeleteField(\n",
    "        in_table=acc_table,\n",
    "        drop_field=\"min_tmpf;RASTERVALU\",\n",
    "        method=\"DELETE_FIELDS\"\n",
    "    )\n",
    "    \n",
    "    # Calculate the squared error\n",
    "    arcpy.management.CalculateField(\n",
    "        in_table=acc_table,\n",
    "        field=\"Sq_error\",\n",
    "        expression=\"math.pow(!GrndTruth! - !Classified!, 2)\",\n",
    "        expression_type=\"PYTHON3\",\n",
    "        code_block=\"\",\n",
    "        field_type=\"FLOAT\",\n",
    "        enforce_domains=\"NO_ENFORCE_DOMAINS\"\n",
    "    )\n",
    "    \n",
    "    # Create a new statistic table and calculate RMSE\n",
    "    arcpy.analysis.Statistics(\n",
    "        in_table=acc_table,\n",
    "        out_table=stat_table,\n",
    "        statistics_fields=\"Sq_error SUM\",\n",
    "        case_field=None,\n",
    "        concatenation_separator=\"\"\n",
    "    )    \n",
    "    arcpy.management.CalculateField(\n",
    "        in_table=stat_table,\n",
    "        field=\"RMSE\",\n",
    "        expression=\"math.sqrt(!SUM_Sq_err! / !FREQUENCY!)\",\n",
    "        expression_type=\"PYTHON3\",\n",
    "        code_block=\"\",\n",
    "        field_type=\"FLOAT\",\n",
    "        enforce_domains=\"NO_ENFORCE_DOMAINS\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists with the raster names of the interpolations with and without extension\n",
    "interpolations = ['IDW.tif', 'Kriging.tif', 'GPI.tif']\n",
    "interpolators  = ['IDW', 'Kriging', 'GPI']\n",
    "\n",
    "# Run the accuracy assesment for each interpolation\n",
    "for i in range(len(interpolations)):\n",
    "    accuracy_assessment(interpolations[i], \"validation_shapefile.shp\")\n",
    "\n",
    "# Merge the accuracy tables     \n",
    "arcpy.management.Merge(\n",
    "    inputs=\"Acc_IDW_stat.dbf;Acc_Kriging_stat.dbf;Acc_GPI_stat.dbf\",\n",
    "    output=\"Accuracy_assessment.dbf\",\n",
    "    field_mappings='Interpolat \"Interpolat\" true true false 255 Text 0 0,First,#;FREQUENCY \"FREQUENCY\" true true false 10 Long 0 10,First,#,Acc_IDW_stat,FREQUENCY,-1,-1,Acc_Kriging_stat,FREQUENCY,-1,-1,Acc_GPI_stat,FREQUENCY,-1,-1;SUM_Sq_err \"SUM_Sq_err\" true true false 19 Double 0 0,First,#,Acc_IDW_stat,SUM_Sq_err,-1,-1,Acc_Kriging_stat,SUM_Sq_err,-1,-1,Acc_GPI_stat,SUM_Sq_err,-1,-1;RMSE \"RMSE\" true true false 13 Float 0 0,First,#,Acc_IDW_stat,RMSE,-1,-1,Acc_Kriging_stat,RMSE,-1,-1,Acc_GPI_stat,RMSE,-1,-1',\n",
    "    add_source=\"NO_SOURCE_INFO\"\n",
    ")\n",
    "\n",
    "# Update the merged table with the name of each interpolator\n",
    "with arcpy.da.UpdateCursor(\"Accuracy_assessment.dbf\", ['Interpolat']) as cursor:\n",
    "    for i, row in enumerate(cursor):\n",
    "        if i < len(interpolators):\n",
    "            row[0] = interpolators[i]\n",
    "        else:\n",
    "            break\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "# Delete the cursor to release locks on the data\n",
    "del cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the interpolator with the lowest RMSE\n",
    "methods = {}\n",
    "fields = [\"Interpolat\", \"RMSE\"]\n",
    "with arcpy.da.SearchCursor('Accuracy_assessment.dbf', fields) as cursor:\n",
    "    for row in cursor:\n",
    "        methods[row[0]] = row[1]\n",
    "\n",
    "best_interpolator = min(methods, key=methods.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, April 11, 2023 5:09:16 PM\",\"Succeeded at Tuesday, April 11, 2023 5:09:16 PM (Elapsed Time: 0.86 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\ArcGIS_2\\\\Lab3\\\\Kriging.shp'>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clip interpolation to MN borders \n",
    "output_clip = os.path.join(wksp, best_interpolator + '_mn.tif')\n",
    "out_raster = arcpy.sa.ExtractByMask(\n",
    "    in_raster=best_interpolator+'.tif',\n",
    "    in_mask_data=\"minnesota.shp\",\n",
    "    extraction_area=\"INSIDE\",\n",
    "    analysis_extent='-97.239102895829 43.499445217943 -89.6516983029999 49.0583312990001 GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]]'\n",
    ")\n",
    "out_raster.save(output_clip)\n",
    "\n",
    "# Convert raster to point shapefile\n",
    "output_point_shp = os.path.join(wksp, best_interpolator + '.shp')\n",
    "arcpy.conversion.RasterToPoint(\n",
    "    in_raster=output_clip,\n",
    "    out_point_features=output_point_shp,\n",
    "    raster_field=\"Value\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save to PostGIS database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to PostGIS database\n",
    "connection = psycopg2.connect(host = '',\n",
    "                              port = '',\n",
    "                              database = '',\n",
    "                              user = '',\n",
    "                              password = '',\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Accuracy assessment table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path and fields of the data to load to the database\n",
    "data = os.path.join(wksp, \"Accuracy_assessment.dbf\")\n",
    "fields = [\"OID\", \"Interpolat\", \"FREQUENCY\", \"SUM_Sq_err\", \"RMSE\"]\n",
    "\n",
    "# Create SQL table\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"DROP TABLE IF EXISTS accuracy_assessment\")\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE accuracy_assessment (\n",
    "        OID INT,\n",
    "        Interpolat VARCHAR,\n",
    "        FREQUENCY INT,\n",
    "        SUM_Sq_err DOUBLE PRECISION,\n",
    "        RMSE DOUBLE PRECISION)\n",
    "\"\"\")\n",
    "\n",
    "# Populate table\n",
    "with arcpy.da.SearchCursor(data, fields) as da_cursor:\n",
    "    for row in da_cursor:\n",
    "        cursor.execute(\"INSERT INTO accuracy_assessment (OID, Interpolat, FREQUENCY, SUM_Sq_err, RMSE) VALUES (%s, %s, %s, %s, %s)\", (row[0], row[1], row[2], row[3], row[4]))\n",
    "\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Best interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table name with the name of the best interpolator\n",
    "point_table = best_interpolator.lower()\n",
    "\n",
    "fields = [\"pointid\", \"grid_code\", \"Shape@WKT\"]\n",
    "\n",
    "# Create SQL table\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(f\"DROP TABLE IF EXISTS {point_table}\")\n",
    "cursor.execute(f\"\"\"\n",
    "    CREATE TABLE {point_table} (\n",
    "        pointid INT,\n",
    "        grid_code DOUBLE PRECISION)\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(f\"\"\"\n",
    "    SELECT AddGeometryColumn('{point_table}', 'geom', 4326, 'POINT', 2)\n",
    "\"\"\")\n",
    "\n",
    "# Populate table\n",
    "with arcpy.da.SearchCursor(output_point_shp, fields) as da_cursor:\n",
    "    for row in da_cursor:\n",
    "        wkt = row[2]\n",
    "        cursor.execute(f\"INSERT INTO {point_table} (pointid, grid_code, geom) VALUES (%s, %s, ST_GeomFromText(%s, 4326))\", (row[0], row[1], wkt))\n",
    "\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Error table for best interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of the shapefile\n",
    "data = os.path.join(wksp, 'Acc_' + best_interpolator + '.shp')\n",
    "\n",
    "# Create the table name to use in PostGIS database\n",
    "table_name = best_interpolator.lower() + '_error_estimation'\n",
    "\n",
    "fields = [\"GrndTruth\", \"Classified\", \"Sq_error\", \"Shape@WKT\"]\n",
    "\n",
    "# Create SQL table\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "cursor.execute(f\"\"\"\n",
    "    CREATE TABLE {table_name} (\n",
    "        GrndTruth DOUBLE PRECISION,\n",
    "        Classified DOUBLE PRECISION,\n",
    "        Sq_error DOUBLE PRECISION)\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(f\"\"\"\n",
    "    SELECT AddGeometryColumn('{table_name}', 'geom', 4326, 'POINT', 2)\n",
    "\"\"\")\n",
    "\n",
    "# Populate table\n",
    "with arcpy.da.SearchCursor(data, fields) as da_cursor:\n",
    "    for row in da_cursor:\n",
    "        wkt = row[3]\n",
    "        cursor.execute(f\"INSERT INTO {table_name} (GrndTruth, Classified, Sq_error, geom) VALUES (%s, %s, %s, ST_GeomFromText(%s, 4326))\", (row[0], row[1], row[2], wkt))\n",
    "\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connection\n",
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
